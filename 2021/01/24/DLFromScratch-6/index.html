<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  
  <title itemprop="name">鱼书笔记 第六章 与学习有关的技巧 | DayDream</title>
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+SerifMerriweather|Merriweather+Sans|Source+Code+Pro|Ubuntu:400,700|Noto+Serif+SC" media="all">
  <link rel="dns-prefetch" href="//cdn.jsdelivr.net">
  <link rel="stylesheet" id="saukra_css-css" href="/css/style.css" type="text/css" media="all">
  <link rel="stylesheet" href="/css/lib.min.css" media="all">
  <link rel="stylesheet" href="/css/font.css" media="all">
  <link rel="stylesheet" href="/css/insight.css" media="all">
  <link rel="stylesheet" href="/css/jquery.fancybox.min.css" media="all">
  <link rel="stylesheet" href="/css/zoom.css" media="all">
  <link rel="stylesheet" type="text/css" href="/css/sharejs.css">
<!--   <link rel="stylesheet" id="saukra_css-css" href="https://2heng.xin/wp-content/cache/autoptimize/css/autoptimize_ad42a61f4c7d4bdd9f91afcff6b5dda5.css
" type="text/css" media="all"> -->
  <script>
  /*Initial Variables*/
  var mashiro_option = new Object();
  var mashiro_global = new Object();
  mashiro_option.NProgressON = true;
  /* 
   * 邮箱信息之类的东西可以填在这里，这些js变量基本都作用于sakura-app.js
   * 这样的设置仅是为了方便在基于PHP开发的主题中设置js变量，既然移植到了Node上，我想或许可以精简这一逻辑吧
   */
  mashiro_option.email_domain = "";
  mashiro_option.email_name = "";
  mashiro_option.cookie_version_control = "";
  mashiro_option.qzone_autocomplete = false;
  mashiro_option.site_name = "DayDream";
  mashiro_option.author_name = "DayDream";
  mashiro_option.site_url = "http://x-quest.xyz";
  mashiro_option.v_appId = "JuIYR9hj83G0JnrHR4X9BA3L-gzGzoHsz";
  mashiro_option.v_appKey = "AaDo6LOfCdsKQyWVT8bzUnml";
  mashiro_option.mathjax = "0";
  mashiro_option.qq_api_url = "https://api.mashiro.top/qqinfo/"; 
  mashiro_option.qq_avatar_api_url = "https://api.mashiro.top/qqinfo/";

  // mashiro_option.jsdelivr_css_src = "https://cdn.jsdelivr.net/gh/moezx/cdn@3.4.5/css/lib.min.css";
  // mashiro_option.float_player_on = true;

  /*End of Initial Variables*/
  </script>
  <script type="text/javascript">
  var bg = "https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/cover/(3).jpg.webp".split(",");
  var bgindex = Math.floor(Math.random()*bg.length);
  if (!!window.ActiveXObject || "ActiveXObject" in window) { //is IE?
    alert('朋友，IE浏览器未适配哦~');
  }
  </script>
  <style type="text/css">
  .hljs-ln{border-collapse:collapse}.hljs-ln td{padding:0}.hljs-ln-n:before{content:attr(data-line-number)}
  </style>
  <style type="text/css">.site-top .lower nav{display:block !important;}.author-profile i,.post-like a,.post-share .show-share,.sub-text,.we-info a,span.sitename,.post-more i:hover,#pagination a:hover,.post-content a:hover,.float-content i:hover{color:#FE9600}.feature i,.download,.navigator i:hover,.links ul li:before,.ar-time i,span.ar-circle,.object,.comment .comment-reply-link,.siren-checkbox-radio:checked + .siren-checkbox-radioInput:after{background:#FE9600}::-webkit-scrollbar-thumb{background:#FE9600}.download,.navigator i:hover,.link-title,.links ul li:hover,#pagination a:hover,.comment-respond input[type='submit']:hover{border-color:#FE9600}.entry-content a:hover,.site-info a:hover,.comment h4 a,#comments-navi a.prev,#comments-navi a.next,.comment h4 a:hover,.site-top ul li a:hover,.entry-title a:hover,#archives-temp h3,span.page-numbers.current,.sorry li a:hover,.site-title a:hover,i.iconfont.js-toggle-search.iconsearch:hover,.comment-respond input[type='submit']:hover{color:#FE9600}.comments .comments-main{display:block !important;}.comments .comments-hidden{display:none !important;}background-position:center center;background-attachment:inherit;}
  </style>
</head>
</html>
<body class="page-template page-template-user page-template-page-analytics page-template-userpage-analytics-php page page-id-1297 chinese-font serif isWebKit">
  <div class="scrollbar" id="bar">
  </div>
  <a href="#" class="cd-top faa-float animated"></a>
  <section id="main-container">
    <div class="headertop filter-dot">
  <div id="banner_wave_1"></div>
  <div id="banner_wave_2"></div>
  <figure id="centerbg" class="centerbg">
    <div class="focusinfo no-select">
      <div class="header-tou">
        <a href="http://x-quest.xyz">
          <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/custom/avatar.jpg">
        </a>
      </div>
      <div class="header-info">
        <p>我脚踩着云朵迎着风</p>
        <div class="top-social_v2">
          <li id="bg-pre">
            <img class="flipx" src="https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/next-b.svg">
          </li>
          
            
              
                <li>
                  <a href="mailto:maxliu7@outlook.com" target="_blank" class="social-github" title="email">
                    <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/social/email.svg">
                  </a>
                </li>
              
            
              
                <li class="wechat">
                  <a href="/#">
                    <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/social/wechat.png">
                  </a>
                  <div class="wechatInner">
                    <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/custom/wechat.png">
                  </div>
                </li>
              
            
              
                <li>
                  <a href="https://du.163.com/share/user/caa5d60f49f44f4d96ede3dd669c91ec?user=caa5d60f49f44f4d96ede3dd669c91ec" target="_blank" class="social-github" title="snailreader">
                    <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/social/snailreader.svg">
                  </a>
                </li>
              
            
          
          <li id="bg-next">
            <img src="https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/next-b.svg">
          </li>
        </div>
      </div>
    </div>
  </figure>
  <div id="video-container" style="">
    <video style="object-fit: fill" id="bgvideo" class="video" video-name="" src="" width="auto" preload="auto">
    </video>
    <div id="video-btn" class="loadvideo videolive">
    </div>
    <div id="video-add">
    </div>
    <div class="video-stu">
    </div>
  </div>
  <div class="headertop-down faa-float animated" onclick="headertop_down()">
    <span>
      <i class="fa fa-chevron-down" aria-hidden="true">
      </i>
    </span>
  </div>
</div>
    <div id="page" class="site wrapper">
      <header class="site-header no-select gizle sabit" role="banner">
  <div class="site-top">
    <div class="site-branding">
      <span class="site-title">
        <span class="logolink moe-mashiro">
          <a href="/">
            <span class="sakurasono"></span>
            <span class="shironeko">DayDream</span>
          </a>
        </span>
      </span>
    </div>
    <div class="searchbox search-form-submit">
      <i class="iconfont js-toggle-search iconsearch icon-search">
      </i>
    </div>
    <div id="show-nav" class="showNav mobile-fit">
      <div class="line line1">
      </div>
      <div class="line line2">
      </div>
      <div class="line line3">
      </div>
    </div>
    <div class="lower-cantiner">
      <div class="lower">
        <nav class="mobile-fit-control hide">
          <ul id="menu-new" class="menu">
            
              <li>
                <a href="/">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-fort-awesome faa-shake" aria-hidden="true"></i>
                    首页
                  </span>
                </a>
                
              </li>
            
              <li>
                <a href="/categories">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-sitemap" aria-hidden="true"></i>
                    分类
                  </span>
                </a>
                
                  <ul class="sub-menu">
                    
                      <li>
                        <a href="/categories/随想/">
                          <i class="fa fa-commenting-o" aria-hidden="true"></i>
                          随想
                        </a>
                      </li>
                    
                      <li>
                        <a href="/categories/英语/">
                          <i class="fa fa-book" aria-hidden="true"></i>
                          英语
                        </a>
                      </li>
                    
                      <li>
                        <a href="/categories/OJ题解/">
                          <i class="fa fa-code" aria-hidden="true"></i>
                          题解
                        </a>
                      </li>
                    
                      <li>
                        <a href="/categories/深度学习/">
                          <i class="fa fa-fire" aria-hidden="true"></i>
                          DL
                        </a>
                      </li>
                    
                      <li>
                        <a href="/categories/数据库/">
                          <i class="fa fa-database" aria-hidden="true"></i>
                          DB
                        </a>
                      </li>
                    
                      <li>
                        <a href="/categories">
                          <i class="fa " aria-hidden="true"></i>
                          more
                        </a>
                      </li>
                    
                  </ul>
                
              </li>
            
              <li>
                <a href="/tags">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa fa-tags" aria-hidden="true"></i>
                    标签
                  </span>
                </a>
                
              </li>
            
              <li>
                <a href="/archives">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-archive faa-shake" aria-hidden="true"></i>
                    归档
                  </span>
                </a>
                
              </li>
            
              <li>
                <a href="javascript:;">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-list-ul faa-vertical" aria-hidden="true"></i>
                    清单
                  </span>
                </a>
                
                  <ul class="sub-menu">
                    
                      <li>
                        <a href="/book">
                          <i class="fa fa-th-list faa-bounce" aria-hidden="true"></i>
                          书单
                        </a>
                      </li>
                    
                      <li>
                        <a href="/music/">
                          <i class="fa fa-headphones" aria-hidden="true"></i>
                          歌单
                        </a>
                      </li>
                    
                  </ul>
                
              </li>
            
              <li>
                <a href="/comment/">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-pencil-square-o faa-tada" aria-hidden="true"></i>
                    留言板
                  </span>
                </a>
                
              </li>
            
              <li>
                <a href="/">
                  <span class="faa-parent animated-hover">
                    <i class="fa  fa-leaf faa-wrench" aria-hidden="true"></i>
                    关于
                  </span>
                </a>
                
                  <ul class="sub-menu">
                    
                      <li>
                        <a href="/about/">
                          <i class="fa fa-meetup" aria-hidden="true"></i>
                          我？
                        </a>
                      </li>
                    
                      <li>
                        <a href="/theme-sakura/">
                          <i class="fa iconfont icon-sakura" aria-hidden="true"></i>
                          主题
                        </a>
                      </li>
                    
                  </ul>
                
              </li>
            
          </ul>
        </nav>
      </div>
    </div>
  </div>
</header>

      <link rel="stylesheet" type="text/css" href="/css/sharejs.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
<div class="pattern-center-blank"></div>

  <div class="pattern-center single-center">
    <!-- 有配图默认渲染第一张 -->
    <div class="pattern-attachment-img lazyload" style="background-image: url(https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/1.png);" src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/loader/orange.progress-bar-stripe-loader.svg" data-src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/1.png">
    </div>
    <header class="pattern-header single-header">
      <h1 class="entry-title">
      鱼书笔记 第六章 与学习有关的技巧</h1>
      <p class="entry-census">
        <span>
          <a href="">
            <img src="">
          </a>
        </span>
        <span>
          <a href=""></a>
        </span>
        <span class="bull">
        ·</span>
        2021-1-24<span class="bull">
        ·</span>
      <span id="busuanzi_value_page_pv"></span>次阅读</p>
    </header>
  </div>

<div id="content" class="site-content">
  <div id="primary" class="content-area">
    <main id="main" class="site-main" role="main">
      <article id="post-1" class="post-1 post type-post status-publish format-standard has-post-thumbnail hentry category-uncategorized">
        <div class="toc"></div>
        <!--<div class="toc-entry-content"><!-- 套嵌目录使用（主要为了支援评论）-->
        
        <div class="entry-content">
          <h1 id="6-1-参数的更新"><a href="#6-1-参数的更新" class="headerlink" title="6.1 参数的更新"></a>6.1 参数的更新</h1><p>前面我们采用的参数更新方法是<strong>随机梯度下降法(SGD)</strong><br>实际上还有很多更新参数的方法:</p>
<p>以函数<script type="math/tex">f(x,y)=\frac{x^2}{20}+y^2</script>为例，以下四种参数更新策略的表现情况如下：<br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/1.png" alt="四种策略"></p>
<h2 id="6-1-1-6-1-3-SGD及其缺点"><a href="#6-1-1-6-1-3-SGD及其缺点" class="headerlink" title="6.1.1-6.1.3 SGD及其缺点"></a>6.1.1-6.1.3 SGD及其缺点</h2><p>SGD的策略是：向梯度的方向更新参数</p>
<pre><code class="lang-python">class SGD:
    def __init__(self, lr=0.01):
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
</code></pre>
<p>但前面的图中，梯度的方向并没有指向损失函数最低的方向，导致其更新效率很低效</p>
<h2 id="6-1-4-Momentum"><a href="#6-1-4-Momentum" class="headerlink" title="6.1.4 Momentum"></a>6.1.4 Momentum</h2><p>Momentum是动量的意思，Momentum的更新与“速度”有关</p>
<script type="math/tex; mode=display">v=\alpha v-\eta\frac{\delta L}{\delta W}</script><p>Momentum的更新值受到上次更新的值以及这次的梯度共同影响</p>
<p>也就是说，当梯度方向和上次参数更新不符合，也就是此时更新在发生“迂回”，与SGD相比，Momentum可以使迂回幅度减小</p>
<h2 id="6-1-5-AdaGrad"><a href="#6-1-5-AdaGrad" class="headerlink" title="6.1.5 AdaGrad"></a>6.1.5 AdaGrad</h2><p><strong>学习率衰减</strong>：学习时，学习率逐渐降低的方法<br>AdaGrad发展了<strong>学习率衰减</strong>的思想，会根据参数来更新学习率</p>
<p>AdaGrad学习率的调整思想：参数更新幅度越大，学习率越小</p>
<script type="math/tex; mode=display">h=h+\frac{\delta L}{\delta W}\odot\frac{\delta L}{\delta W}</script><script type="math/tex; mode=display">W=W-\eta\frac{1}{\sqrt{h}}\frac{\delta L}{\delta W}</script><p>h会记录之前所有梯度的平方和，所以学习进行越久，学习率会越接近于0</p>
<pre><code class="lang-python">
class AdaGrad:

    &quot;&quot;&quot;AdaGrad&quot;&quot;&quot;
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None

    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)

        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
</code></pre>
<h2 id="6-1-6-Adam"><a href="#6-1-6-Adam" class="headerlink" title="6.1.6 Adam"></a>6.1.6 Adam</h2><p>Adam参考了AdaGrad和Momentum两种策略</p>
<pre><code class="lang-python">
class Adam:

    &quot;&quot;&quot;Adam (http://arxiv.org/abs/1412.6980v8)&quot;&quot;&quot;

    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.v = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1
        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         

        for key in params.keys():
            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)
            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])

            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)

            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias
            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias
            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)
</code></pre>
<h1 id="6-2-权重的初始值"><a href="#6-2-权重的初始值" class="headerlink" title="6.2 权重的初始值"></a>6.2 权重的初始值</h1><h2 id="6-2-1-初始权重可以设为0吗"><a href="#6-2-1-初始权重可以设为0吗" class="headerlink" title="6.2.1 初始权重可以设为0吗"></a>6.2.1 初始权重可以设为0吗</h2><p>减小权重的值可以抑制过拟合的发生（具体原因在之后的章节会解释）。但初始权重可以设为0吗？</p>
<p><em>注：查阅资料了解到，权重可以取负值，但这里“减少权重的值”指的是绝对值还是数值呢？</em></p>
<p>答案是：不可以设为0.确切地说，权重不应该设计成一样的值。（起码在梯度下降算法时是这样的）</p>
<p>假设：第一层和第二层之间的权重全部设为0，那么第二层接收到的值是相同的。</p>
<p>那么，当反向传播时，第二层返回的导数也是相同的。</p>
<p>那么，第二层权重的更新幅度也是相同的。</p>
<p>这样就使神经网络失去了意义——神经网络必须要有复杂的权重才有意义。</p>
<h2 id="6-2-2-隐藏层的激活值分布"><a href="#6-2-2-隐藏层的激活值分布" class="headerlink" title="6.2.2 隐藏层的激活值分布"></a>6.2.2 隐藏层的激活值分布</h2><p>解释一下隐藏层的激活值：就是隐藏层激活函数的输出数据。<br>已经知道，神经网络的权重需要设为满足高斯分布的值。那么标准差应该设为多少呢？</p>
<p>下面构造的神经网络测试了标准差为1的情况：</p>
<pre><code class="lang-python"># coding: utf-8
import numpy as np
import matplotlib.pyplot as plt


def sigmoid(x):
    return 1 / (1 + np.exp(-x))


def ReLU(x):
    return np.maximum(0, x)


def tanh(x):
    return np.tanh(x) #双曲正切函数

input_data = np.random.randn(1000, 100)  # 1000个输入数据
node_num = 100  # 每个隐藏层的神经元数目
hidden_layer_size = 5  # 隐藏层数
activations = {}  # 结果保存的位置

x = input_data

for i in range(hidden_layer_size):#注意这个循环包括了十几行语句哦！
    if i != 0:
        x = activations[i-1]

    #实验！
    w = np.random.randn(node_num, node_num) * 1
    # w = np.random.randn(node_num, node_num) * 0.01
    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)
    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)


    a = np.dot(x, w)


    # 活性化関数の種類も変えて実験しよう！
    z = sigmoid(a)
    # z = ReLU(a)
    # z = tanh(a)

    activations[i] = z

# ヒストグラムを描画
for i, a in activations.items():
    plt.subplot(1, len(activations), i+1)
    plt.title(str(i+1) + &quot;-layer&quot;)
    if i != 0: plt.yticks([], [])
    # plt.xlim(0.1, 1)
    # plt.ylim(0, 7000)
    plt.hist(a.flatten(), 30, range=(0,1))
plt.show()
</code></pre>
<p>下面展示的是标准差为1、0.01、<script type="math/tex">\sqrt{\frac{1}{n}}</script>、<script type="math/tex">\sqrt{\frac{2}{n}}</script>时的激活值分布：<br>（注：n是上一层的神经元数。比如对于第1层的初始值，应使用第0层的神经元数）<br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/2.png" alt="1"><br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/3.png" alt="2"><br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/4.png" alt="3"><br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/5.png" alt="4"></p>
<p>梯度消失：这里使用的是sigmoid函数，当激活值偏向0或1时，导数会接近于0，这样就发生了梯度消失问题。<br>图1便是这种情况<br>表现力缺失：如果激活值集中于某几个值，那么大量的神经元就没有存在的意义了，这称为<strong>表现力缺失</strong><br>图1、2都有表现力缺失的问题</p>
<p>所以标准差设为<script type="math/tex">\sqrt{\frac{1}{n}}</script>、<script type="math/tex">\sqrt{\frac{2}{n}}</script>或许是更好的选择</p>
<ul>
<li>当激活函数为sigmoid或者tanh时，使用标准差为<script type="math/tex">\sqrt{\frac{1}{n}}</script>的初始值</li>
<li>当激活函数为ReLU函数时，使用标准差为<script type="math/tex">\sqrt{\frac{2}{n}}</script>的初始值</li>
</ul>
<h1 id="6-3-Batch-Normalization"><a href="#6-3-Batch-Normalization" class="headerlink" title="6.3 Batch Normalization"></a>6.3 Batch Normalization</h1><p>前面的初始值设定的目标是：激活值有一定的“广度”<br>那么我们可不可以刻意提高这个“广度”来帮助学习的进行呢？ 由此，出现了BatchNormalization方法<br>Batch Norm有以下优点：</p>
<ul>
<li>使学习快速进行（可以增大学习率）</li>
<li>不那么依赖初始值</li>
<li>抑制过拟合</li>
</ul>
<p>Batch Norm的方法是：向神经网络中插入若干个Batch Norm层，该层用于对数据进行正规化。<br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/6.png" alt="BatchNorm使用"></p>
<p>正规化：使输出数据均值为0、方差为1</p>
<script type="math/tex; mode=display">\mu_{B}$$:均值
$$\sigma^{2}_{B}$$:方差

输出函数：
$$x_i=\frac{x_i-\mu_B}{\sqrt{\sigma^2+\epsilon}}</script><p>其中<script type="math/tex">\epsilon</script>是一个微小的接近0的值，加上它是为了避免分母为0</p>
<p>以下代码用于对batch-norm的评估</p>
<pre><code class="lang-python"># coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from common.multi_layer_net_extend import MultiLayerNetExtend
from common.optimizer import SGD, Adam

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

# 学習データを削減
x_train = x_train[:1000]
t_train = t_train[:1000]

max_epochs = 20
train_size = x_train.shape[0]
batch_size = 100
learning_rate = 0.01


def __train(weight_init_std):
    bn_network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, 
                                    weight_init_std=weight_init_std, use_batchnorm=True)
    network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10,
                                weight_init_std=weight_init_std)
    optimizer = SGD(lr=learning_rate)

    train_acc_list = []
    bn_train_acc_list = []

    iter_per_epoch = max(train_size / batch_size, 1)
    epoch_cnt = 0

    for i in range(1000000000):
        batch_mask = np.random.choice(train_size, batch_size)
        x_batch = x_train[batch_mask]
        t_batch = t_train[batch_mask]

        for _network in (bn_network, network):
            grads = _network.gradient(x_batch, t_batch)
            optimizer.update(_network.params, grads)

        if i % iter_per_epoch == 0:
            train_acc = network.accuracy(x_train, t_train)
            bn_train_acc = bn_network.accuracy(x_train, t_train)
            train_acc_list.append(train_acc)
            bn_train_acc_list.append(bn_train_acc)

            print(&quot;epoch:&quot; + str(epoch_cnt) + &quot; | &quot; + str(train_acc) + &quot; - &quot; + str(bn_train_acc))

            epoch_cnt += 1
            if epoch_cnt &gt;= max_epochs:
                break

    return train_acc_list, bn_train_acc_list


# 3.グラフの描画==========
weight_scale_list = np.logspace(0, -4, num=16)
x = np.arange(max_epochs)

for i, w in enumerate(weight_scale_list):
    print( &quot;============== &quot; + str(i+1) + &quot;/16&quot; + &quot; ==============&quot;)
    train_acc_list, bn_train_acc_list = __train(w)

    plt.subplot(4,4,i+1)
    plt.title(&quot;W:&quot; + str(w))
    if i == 15:
        plt.plot(x, bn_train_acc_list, label=&#39;Batch Normalization&#39;, markevery=2)
        plt.plot(x, train_acc_list, linestyle = &quot;--&quot;, label=&#39;Normal(without BatchNorm)&#39;, markevery=2)
    else:
        plt.plot(x, bn_train_acc_list, markevery=2)
        plt.plot(x, train_acc_list, linestyle=&quot;--&quot;, markevery=2)

    plt.ylim(0, 1.0)
    if i % 4:
        plt.yticks([])
    else:
        plt.ylabel(&quot;accuracy&quot;)
    if i &lt; 12:
        plt.xticks([])
    else:
        plt.xlabel(&quot;epochs&quot;)
    plt.legend(loc=&#39;lower right&#39;)

plt.show()
</code></pre>
<p>运行结果：<br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/7.png" alt="batchNorm效果评估"></p>
<p>实线为使用batch norm 。虚线为不使用。</p>
<h1 id="6-4-正则化"><a href="#6-4-正则化" class="headerlink" title="6.4 正则化"></a>6.4 正则化</h1><h2 id="6-4-1-过拟合"><a href="#6-4-1-过拟合" class="headerlink" title="6.4.1 过拟合"></a>6.4.1 过拟合</h2><p>过拟合是指：训练出的模型只能拟合训练数据，但不能很好地拟合训练数据之外的数据的情况</p>
<p>发生过拟合的原因有：</p>
<ul>
<li>模型具有大量参数，表现力强</li>
<li>训练数据少</li>
</ul>
<p>下面的代码模拟了过拟合的情况:(采用300个训练数据，7×100的神经网络)</p>
<pre><code class="lang-python"># coding: utf-8
import os
import sys

sys.path.append(os.pardir)  
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from common.multi_layer_net import MultiLayerNet
from common.optimizer import SGD

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)


x_train = x_train[:300]
t_train = t_train[:300]


weight_decay_lambda = 0.1
# ====================================================

network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,
                        weight_decay_lambda=weight_decay_lambda)
optimizer = SGD(lr=0.01)

max_epochs = 201
train_size = x_train.shape[0]
batch_size = 100

train_loss_list = []
train_acc_list = []
test_acc_list = []

iter_per_epoch = max(train_size / batch_size, 1)
epoch_cnt = 0

for i in range(1000000000):
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    grads = network.gradient(x_batch, t_batch)
    optimizer.update(network.params, grads)

    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train)
        test_acc = network.accuracy(x_test, t_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)

        print(&quot;epoch:&quot; + str(epoch_cnt) + &quot;, train acc:&quot; + str(train_acc) + &quot;, test acc:&quot; + str(test_acc))

        epoch_cnt += 1
        if epoch_cnt &gt;= max_epochs:
            break



markers = {&#39;train&#39;: &#39;o&#39;, &#39;test&#39;: &#39;s&#39;}
x = np.arange(max_epochs)
plt.plot(x, train_acc_list, marker=&#39;o&#39;, label=&#39;train&#39;, markevery=10)
plt.plot(x, test_acc_list, marker=&#39;s&#39;, label=&#39;test&#39;, markevery=10)
plt.xlabel(&quot;epochs&quot;)
plt.ylabel(&quot;accuracy&quot;)
plt.ylim(0, 1.0)
plt.legend(loc=&#39;lower right&#39;)
plt.show()
</code></pre>
<p>运行结果图像:<br><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/8.png" alt="overfit"></p>
<h2 id="6-4-2-权值衰减"><a href="#6-4-2-权值衰减" class="headerlink" title="6.4.2 权值衰减"></a>6.4.2 权值衰减</h2><p>很多过拟合是由于权重参数取值过大才发生的。<br>为了抑制这种过拟合，便可以采取<strong>权值衰减</strong>的方法，即抑制权重参数过大的现象</p>
<p>“学习”是不断调整参数来使损失函数减小的过程。假如把权重参数加进损失函数里，就可以在减小损失函数时兼顾减小权重了。</p>
<p>我们定义L2范数：</p>
<script type="math/tex; mode=display">\frac{1}{2}\lambda W^2</script><p>乘以<script type="math/tex">\frac{1}{2}</script>的目的是为了在求导时得到规整的值</p>
<p>以下为权值衰减时的随书源码。<br>(仅需注意loss函数中的weight_dacay)</p>
<pre><code class="lang-python"># coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定
import numpy as np
from collections import OrderedDict
from common.layers import *
from common.gradient import numerical_gradient


class MultiLayerNet:
    &quot;&quot;&quot;全結合による多層ニューラルネットワーク

    Parameters
    ----------
    input_size : 入力サイズ（MNISTの場合は784）
    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）
    output_size : 出力サイズ（MNISTの場合は10）
    activation : &#39;relu&#39; or &#39;sigmoid&#39;
    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）
        &#39;relu&#39;または&#39;he&#39;を指定した場合は「Heの初期値」を設定
        &#39;sigmoid&#39;または&#39;xavier&#39;を指定した場合は「Xavierの初期値」を設定
    weight_decay_lambda : Weight Decay（L2ノルム）の強さ
    &quot;&quot;&quot;
    def __init__(self, input_size, hidden_size_list, output_size,
                 activation=&#39;relu&#39;, weight_init_std=&#39;relu&#39;, weight_decay_lambda=0):
        self.input_size = input_size
        self.output_size = output_size
        self.hidden_size_list = hidden_size_list
        self.hidden_layer_num = len(hidden_size_list)
        self.weight_decay_lambda = weight_decay_lambda
        self.params = {}

        # 重みの初期化
        self.__init_weight(weight_init_std)

        # レイヤの生成
        activation_layer = {&#39;sigmoid&#39;: Sigmoid, &#39;relu&#39;: Relu}
        self.layers = OrderedDict()
        for idx in range(1, self.hidden_layer_num+1):
            self.layers[&#39;Affine&#39; + str(idx)] = Affine(self.params[&#39;W&#39; + str(idx)],
                                                      self.params[&#39;b&#39; + str(idx)])
            self.layers[&#39;Activation_function&#39; + str(idx)] = activation_layer[activation]()

        idx = self.hidden_layer_num + 1
        self.layers[&#39;Affine&#39; + str(idx)] = Affine(self.params[&#39;W&#39; + str(idx)],
            self.params[&#39;b&#39; + str(idx)])

        self.last_layer = SoftmaxWithLoss()

    def __init_weight(self, weight_init_std):
        &quot;&quot;&quot;重みの初期値設定

        Parameters
        ----------
        weight_init_std : 重みの標準偏差を指定（e.g. 0.01）
            &#39;relu&#39;または&#39;he&#39;を指定した場合は「Heの初期値」を設定
            &#39;sigmoid&#39;または&#39;xavier&#39;を指定した場合は「Xavierの初期値」を設定
        &quot;&quot;&quot;
        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]
        for idx in range(1, len(all_size_list)):
            scale = weight_init_std
            if str(weight_init_std).lower() in (&#39;relu&#39;, &#39;he&#39;):
                scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLUを使う場合に推奨される初期値
            elif str(weight_init_std).lower() in (&#39;sigmoid&#39;, &#39;xavier&#39;):
                scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoidを使う場合に推奨される初期値

            self.params[&#39;W&#39; + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])
            self.params[&#39;b&#39; + str(idx)] = np.zeros(all_size_list[idx])

    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x

    def loss(self, x, t):
        &quot;&quot;&quot;損失関数を求める

        Parameters
        ----------
        x : 入力データ
        t : 教師ラベル

        Returns
        -------
        損失関数の値
        &quot;&quot;&quot;
        y = self.predict(x)

        weight_decay = 0
        for idx in range(1, self.hidden_layer_num + 2):
            W = self.params[&#39;W&#39; + str(idx)]
            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W ** 2)

        return self.last_layer.forward(y, t) + weight_decay

    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        if t.ndim != 1 : t = np.argmax(t, axis=1)

        accuracy = np.sum(y == t) / float(x.shape[0])
        return accuracy

    def numerical_gradient(self, x, t):
        &quot;&quot;&quot;勾配を求める（数値微分）

        Parameters
        ----------
        x : 入力データ
        t : 教師ラベル

        Returns
        -------
        各層の勾配を持ったディクショナリ変数
            grads[&#39;W1&#39;]、grads[&#39;W2&#39;]、...は各層の重み
            grads[&#39;b1&#39;]、grads[&#39;b2&#39;]、...は各層のバイアス
        &quot;&quot;&quot;
        loss_W = lambda W: self.loss(x, t)

        grads = {}
        for idx in range(1, self.hidden_layer_num+2):
            grads[&#39;W&#39; + str(idx)] = numerical_gradient(loss_W, self.params[&#39;W&#39; + str(idx)])
            grads[&#39;b&#39; + str(idx)] = numerical_gradient(loss_W, self.params[&#39;b&#39; + str(idx)])

        return grads

    def gradient(self, x, t):
        &quot;&quot;&quot;勾配を求める（誤差逆伝搬法）

        Parameters
        ----------
        x : 入力データ
        t : 教師ラベル

        Returns
        -------
        各層の勾配を持ったディクショナリ変数
            grads[&#39;W1&#39;]、grads[&#39;W2&#39;]、...は各層の重み
            grads[&#39;b1&#39;]、grads[&#39;b2&#39;]、...は各層のバイアス
        &quot;&quot;&quot;
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.last_layer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()
        for layer in layers:
            dout = layer.backward(dout)

        # 設定
        grads = {}
        for idx in range(1, self.hidden_layer_num+2):
            grads[&#39;W&#39; + str(idx)] = self.layers[&#39;Affine&#39; + str(idx)].dW + self.weight_decay_lambda * self.layers[&#39;Affine&#39; + str(idx)].W
            grads[&#39;b&#39; + str(idx)] = self.layers[&#39;Affine&#39; + str(idx)].db

        return grads
</code></pre>
<p>用于实验的代码不表。<br>运行结果：</p>
<p><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/9.png" alt="overfit"><br>虽然预测能力没有明显提高，但过拟合受到了抑制。</p>
<h2 id="6-4-3-DropOut"><a href="#6-4-3-DropOut" class="headerlink" title="6.4.3 DropOut"></a>6.4.3 DropOut</h2><p>当模型很复杂(神经元数量很多)时，权值衰减法效果也不太明显了。<br>DropOut方法可以在复杂的模型中也有较好效果。<br>思路：<br>Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。<br>这篇文章讲得挺有趣的：<a href="https://zhuanlan.zhihu.com/p/77609689" target="_blank" rel="noopener">知乎《什么是dropout》</a><br>具体是：<br>训练模型时，随机排除一定比例的神经元。<br>而使用模型时，不排除任何神经元，但要乘以训练时的那个排除比例。<br>具体实现不表。</p>
<h1 id="6-5-超参数的验证"><a href="#6-5-超参数的验证" class="headerlink" title="6.5 超参数的验证"></a>6.5 超参数的验证</h1><p>超参数（如学习率、神经元数量）非常重要，但找到合适的取值比较困难。本节介绍如何尽可能高效地选择超参数。</p>
<h2 id="6-5-1-验证数据"><a href="#6-5-1-验证数据" class="headerlink" title="6.5.1 验证数据"></a>6.5.1 验证数据</h2><p>切记：一定<strong>不要使用训练数据来验证</strong>超参数，否则会发生过拟合。</p>
<p>一般选取专门数据来验证超参数，称之为<strong>验证数据</strong></p>
<ul>
<li>训练数据用于学习（调整权重参数）</li>
<li>验证数据用于验证超参数</li>
<li>测试数据用于验证泛化能力（理想情况下，测试数据最好只使用一次）</li>
</ul>
<p>以下代码用于选择出验证数据：</p>
<pre><code class="lang-python">
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

# 这里还有一个函数，用于把数据打乱，实现不表。
# 検証データの分離
validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)
x_train, t_train = shuffle_dataset(x_train, t_train)
x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]
</code></pre>
<h2 id="6-5-2-超参数的最优化"><a href="#6-5-2-超参数的最优化" class="headerlink" title="6.5.2 超参数的最优化"></a>6.5.2 超参数的最优化</h2><p>步骤：</p>
<ul>
<li>1，设定超参数的范围（很粗略就可以，比如<script type="math/tex">10^{-3}</script>~<script type="math/tex">10^{3}</script>）</li>
<li>2, 从设定的超参数范围内随机采样</li>
<li>3，完成学习步骤，再利用验证数据进行超参数验证。但注意，需要把epoch设定得比较小（因为只是要验证超参数，没必要完整地完成学习过程）</li>
<li>4，不断重复2、3步骤，逐渐缩小超参数范围</li>
</ul>
<p>以上介绍的是一种经验式的做法，更精炼的方法可能是<strong>贝叶斯最优化</strong>方法</p>
<h2 id="6-5-3-超参数最优化的实现"><a href="#6-5-3-超参数最优化的实现" class="headerlink" title="6.5.3 超参数最优化的实现"></a>6.5.3 超参数最优化的实现</h2><p>代码如下：</p>
<p>我们设定权值衰减系数为<script type="math/tex">10^{-8}</script>~<script type="math/tex">10^{-4}</script>,学习率为<script type="math/tex">10^{-6}</script>~<script type="math/tex">10^{-2}</script></p>
<pre><code class="lang-python"># coding: utf-8
import sys, os
sys.path.append(os.pardir)  
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from common.multi_layer_net import MultiLayerNet
from common.util import shuffle_dataset
from common.trainer import Trainer

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)


x_train = x_train[:500]
t_train = t_train[:500]


validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)
x_train, t_train = shuffle_dataset(x_train, t_train)
x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]


def __train(lr, weight_decay, epocs=50):
    network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],
                            output_size=10, weight_decay_lambda=weight_decay)
    trainer = Trainer(network, x_train, t_train, x_val, t_val,
                      epochs=epocs, mini_batch_size=100,
                      optimizer=&#39;sgd&#39;, optimizer_param={&#39;lr&#39;: lr}, verbose=False)
    trainer.train()

    return trainer.test_acc_list, trainer.train_acc_list


# ハイパーパラメータのランダム探索======================================
optimization_trial = 100
results_val = {}
results_train = {}
for _ in range(optimization_trial):
    # 探索したハイパーパラメータの範囲を指定===============
    weight_decay = 10 ** np.random.uniform(-8, -4)
    lr = 10 ** np.random.uniform(-6, -2)
    # ================================================

    val_acc_list, train_acc_list = __train(lr, weight_decay)
    print(&quot;val acc:&quot; + str(val_acc_list[-1]) + &quot; | lr:&quot; + str(lr) + &quot;, weight decay:&quot; + str(weight_decay))
    key = &quot;lr:&quot; + str(lr) + &quot;, weight decay:&quot; + str(weight_decay)
    results_val[key] = val_acc_list
    results_train[key] = train_acc_list

# グラフの描画========================================================
print(&quot;=========== Hyper-Parameter Optimization Result ===========&quot;)
graph_draw_num = 20
col_num = 5
row_num = int(np.ceil(graph_draw_num / col_num))
i = 0

for key, val_acc_list in sorted(results_val.items(), key=lambda x:x[1][-1], reverse=True):
    print(&quot;Best-&quot; + str(i+1) + &quot;(val acc:&quot; + str(val_acc_list[-1]) + &quot;) | &quot; + key)

    plt.subplot(row_num, col_num, i+1)
    plt.title(&quot;Best-&quot; + str(i+1))
    plt.ylim(0.0, 1.0)
    if i % 5: plt.yticks([])
    plt.xticks([])
    x = np.arange(len(val_acc_list))
    plt.plot(x, val_acc_list)
    plt.plot(x, results_train[key], &quot;--&quot;)
    i += 1

    if i &gt;= graph_draw_num:
        break

plt.show()
</code></pre>
<p>  =========== Hyper-Parameter Optimization Result ===========<br>  Best-1(val acc:0.76) | lr:0.009849135982779367, weight decay:8.371126751378459e-08<br>  Best-2(val acc:0.72) | lr:0.008465895756364618, weight decay:5.599344465686115e-06<br>  Best-3(val acc:0.68) | lr:0.007463998530287792, weight decay:5.434999294796928e-06<br>  Best-4(val acc:0.61) | lr:0.0059275054234944596, weight decay:7.217143257829478e-06<br>  Best-5(val acc:0.54) | lr:0.003222780855302866, weight decay:1.5494577799060805e-05<br>  Best-6(val acc:0.44) | lr:0.0030073951251438093, weight decay:1.1708444261159714e-07<br>  Best-7(val acc:0.43) | lr:0.0021005853382527672, weight decay:7.179899890144345e-05<br>  Best-8(val acc:0.41) | lr:0.0031555490566781397, weight decay:1.1570768776264578e-07<br>  Best-9(val acc:0.35) | lr:0.002751737792997746, weight decay:1.0030928213849842e-06<br>  Best-10(val acc:0.35) | lr:0.002530549949995383, weight decay:1.8429003004503172e-06<br>  Best-11(val acc:0.34) | lr:0.003805297187578114, weight decay:2.9763771933588664e-08<br>  Best-12(val acc:0.32) | lr:0.0018044953610692638, weight decay:1.633388106435468e-08<br>  Best-13(val acc:0.31) | lr:0.003299654651673116, weight decay:1.3468893175173874e-05<br>  Best-14(val acc:0.26) | lr:0.0013745036090004102, weight decay:3.349507714291408e-07<br>  Best-15(val acc:0.24) | lr:0.002100802278572699, weight decay:2.5164597992132576e-07<br>  Best-16(val acc:0.22) | lr:0.001228741710146572, weight decay:4.510320818341757e-05<br>  Best-17(val acc:0.21) | lr:0.0015933677262844985, weight decay:4.13572569703448e-08<br>  Best-18(val acc:0.2) | lr:0.0009158024090896935, weight decay:3.5597450057769847e-06<br>  Best-19(val acc:0.19) | lr:0.0003545544553829815, weight decay:3.6634747810567344e-05<br>  Best-20(val acc:0.19) | lr:5.3171828783850735e-05, weight decay:2.296395116949957e-06</p>
<p><img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/2021-1-20-1/10.png" alt="超参数验证"><br>实线是验证数据，虚线是训练数据<br>可以看到，best5之前的学习效果都比较好</p>
<p>参照best-1到 best-5的数据，可以将学习率范围缩减到0.001到0.1， 权重衰减参数范围缩减到<script type="math/tex">10^{-7}</script>到<script type="math/tex">10^{-5}</script></p>

        </div>
        <!-- .entry-content -->
        <div style="text-align:center; width: 100%" class="social-share share-mobile" data-disabled="diandian, tencent"></div>
        <footer class="post-footer">
          <div class="post-lincenses"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="nofollow"><i class="fa fa-creative-commons" aria-hidden="true"></i> 知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a></div>
          <div class="post-tags">
          </div>
          <div class="post-share">
            <div class="social-share sharehidden share-component"></div>
            <i class="iconfont show-share icon-forward"></i>
          </div>
        </footer><!-- .entry-footer -->
      </article>
      <!-- #post-## -->
      <div class="toc" style="background: none;"></div>
      <section class="post-squares nextprev">
        
          
            <div class="post-nepre half previous">
          
            <a href="/2021/01/26/jsNote-8/" rel="prev">
              <div class="background">
                <img class="lazyload" src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/loader/orange.progress-bar-stripe-loader.svg" data-src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/bg/13.png" style="width: 100%; height: 100%; object-fit: cover; pointer-events: none;" onerror="imgError(this,3)" src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/bg/13.png">
              </div>
              <span class="label">
              Previous Post</span>
              <div class="info">
                <h3>
                JS笔记（八） math/一些语法</h3>
                <hr>
              </div>
            </a>
          </div>
        
        
          
            <div class="post-nepre half next">
          
            <a href="/2021/01/24/jsNote-3/" rel="next">
              <div class="background">
                <img class="lazyload" src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/loader/orange.progress-bar-stripe-loader.svg" data-src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/bg/9.png" style="width: 100%; height: 100%; object-fit: cover; pointer-events: none;" onerror="imgError(this,3)" src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/post/bg/9.png">
              </div>
              <span class="label">
              Next Post</span>
              <div class="info">
                <h3>
                JS笔记（三）</h3>
                <hr>
              </div>
            </a>
          </div>
        
      </section>
      
<div id="vcomments"></div>
<script>
  window.onload = function(){
      var valine = new Valine();
      valine.init({
        el: '#vcomments',
        appId: "JuIYR9hj83G0JnrHR4X9BA3L-gzGzoHsz",
        appKey: "AaDo6LOfCdsKQyWVT8bzUnml",
        path: window.location.pathname,
        placeholder: "你是我一生只会遇见一次的惊喜 ..."
      })
  }
</script>

      <section class="author-profile">
        <div class="info" itemprop="author" itemscope="" itemtype="https://schema.org/Person">
          <a href="" class="profile gravatar"><img src="" itemprop="image" alt="" height="70" width="70"></a>
          <div class="meta">
            <span class="title">Author</span>
            <h3 itemprop="name">
            <a href="" itemprop="url" rel="author"></a>
            </h3>
          </div>
        </div>
        <hr>
        <p><i class="iconfont icon-write"></i></p>
      </section>
    </main><!-- #main -->
  </div><!-- #primary -->
</div>


  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>


    </div>    
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="请输入关键词..."/>
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            // PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
    <!-- <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 断梦三生<br>
      powered_by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer> -->
<footer id="colophon" class="site-footer" role="contentinfo">
  <div class="site-info">
    <div class="footertext">
      <div class="img-preload">
        <img src="https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/wordpress-rotating-ball-o.svg">
        <img src="https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/disqus-preloader.svg">
      </div>
      <p style="color: #666666;">&copy 2019 Max L ♥</p>
    </div>
    <div class="footer-device">

    </div>
  </div><!-- .site-info -->
</footer>



<!-- <script src="/js/tocbot.js"></script> -->
<script type="text/javascript" src="/js/lib.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script type="text/javascript" src="/js/InsightSearch.js"></script>
<script type="text/javascript" src="/js/jquery.fancybox.min.js"></script>
<script type="text/javascript" src="/js/zoom.min.js"></script>
<script type="text/javascript" src="/js/sakura-app.js"></script>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine@1.3.4/dist/Valine.min.js'></script>
<script src="/js/botui.js"></script>
<!-- 不蒜子 网页计数器 -->
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script> -->
<script type="text/javascript">
/* <![CDATA[ */
if (/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  var Poi = {"pjax":"1","movies":{"url": "https://cdn.jsdelivr.net/gh/honjun/hojun@1.2","name":"Unbroken.mp4","live":"close"},"windowheight":"fixed","codelamp":"close","ajaxurl":"","order":"asc","formpostion":"bottom"};
} else {
  var Poi = {"pjax":"1","movies":{"url": "https://cdn.jsdelivr.net/gh/honjun/hojun@1.2","name":"Unbroken.mp4","live":"open"},"windowheight":"auto","codelamp":"close","ajaxurl":"","order":"asc","formpostion":"bottom"};
}
/* ]]> */

</script>
<script>
$(document).ready(function() {
  if ($(".toc").length > 0 && document.body.clientWidth > 1200) {
    if ($(".pattern-center").length > 0) { //有图的情况
      tocbot.init({
          // Where to render the table of contents.
          tocSelector: '.toc', // 放置目录的容器
          // Where to grab the headings to build the table of contents.
          contentSelector: '.entry-content', // 正文内容所在
          // Which headings to grab inside of the contentSelector element.
          scrollSmooth: true,
          headingSelector: 'h1, h2, h3, h4, h5', // 需要索引的标题级别
          headingsOffset: -400,
          scrollSmoothOffset: -85
      });
    } else {
      tocbot.init({
          // Where to render the table of contents.
          tocSelector: '.toc', // 放置目录的容器
          // Where to grab the headings to build the table of contents.
          contentSelector: '.entry-content', // 正文内容所在
          // Which headings to grab inside of the contentSelector element.
          scrollSmooth: true,
          headingSelector: 'h1, h2, h3, h4, h5', // 需要索引的标题级别
          headingsOffset: -85,
          scrollSmoothOffset: -85
      });
    }
    var offsetTop = $('.toc').offset().top - 95;
    window.onscroll = function() {
      var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop;
      if (scrollTop >= offsetTop) {
        $('.toc').addClass('toc-fixed');
      } else {
        $('.toc').removeClass('toc-fixed');
      }
    }
  }
});
</script>

    <div class="openNav no-select" style="height: 50px;">
      <div class="iconflat no-select" style="width: 50px; height: 50px;">
        <div class="icon"></div>
      </div>
      <div class="site-branding search-form-submit">
        <i class="iconfont js-toggle-search iconsearch icon-search"></i>
      </div>
    </div>
  </section>
  <div id="mo-nav" class="">
  <div class="m-avatar">
    <img src="https://cdn.jsdelivr.net/gh/ovenKiller/CDN/img/custom/avatar.jpg">
  </div>
  <p style="text-align: center; color: #333; font-weight: 900; font-family: 'Ubuntu', sans-serif; letter-spacing: 1.5px">DayDream</p>
  <p style="text-align: center; word-spacing: 20px;">
    
      
        <a href="https://qm.qq.com/cgi-bin/qm/qr?k=OKbDbzqI5VkiSEunPQoWG9F2yxDGaYQD&noverify=0" class="fa fa-qq" target="_blank" style="color: #25c6fe; margin-left:20px"></a>
      
        <a href="http://music.163.com/m/user/home?id=67715923" class="fa " target="_blank" style="color: #; margin-left:20px"></a>
      
        <a href="https://du.163.com/share/user/caa5d60f49f44f4d96ede3dd669c91ec?user=caa5d60f49f44f4d96ede3dd669c91ec" class="fa " target="_blank" style="color: #; margin-left:20px"></a>
      
    
  </p>
  <ul id="menu-new-1" class="menu">
    
      <li>
        <a href="/">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-fort-awesome faa-shake" aria-hidden="true"></i>
            首页
          </span>
        </a>
        
      </li>
    
      <li>
        <a href="/categories">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-sitemap" aria-hidden="true"></i>
            分类
          </span>
        </a>
        
          <ul class="sub-menu">
            
              <li>
                <a href="/categories/随想/">
                  <i class="fa fa-commenting-o" aria-hidden="true"></i>
                  随想
                </a>
              </li>
            
              <li>
                <a href="/categories/英语/">
                  <i class="fa fa-book" aria-hidden="true"></i>
                  英语
                </a>
              </li>
            
              <li>
                <a href="/categories/OJ题解/">
                  <i class="fa fa-code" aria-hidden="true"></i>
                  题解
                </a>
              </li>
            
              <li>
                <a href="/categories/深度学习/">
                  <i class="fa fa-fire" aria-hidden="true"></i>
                  DL
                </a>
              </li>
            
              <li>
                <a href="/categories/数据库/">
                  <i class="fa fa-database" aria-hidden="true"></i>
                  DB
                </a>
              </li>
            
              <li>
                <a href="/categories">
                  <i class="fa " aria-hidden="true"></i>
                  more
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li>
        <a href="/tags">
          <span class="faa-parent animated-hover">
            <i class="fa  fa fa-tags" aria-hidden="true"></i>
            标签
          </span>
        </a>
        
      </li>
    
      <li>
        <a href="/archives">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-archive faa-shake" aria-hidden="true"></i>
            归档
          </span>
        </a>
        
      </li>
    
      <li>
        <a href="javascript:;">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-list-ul faa-vertical" aria-hidden="true"></i>
            清单
          </span>
        </a>
        
          <ul class="sub-menu">
            
              <li>
                <a href="/book">
                  <i class="fa fa-th-list faa-bounce" aria-hidden="true"></i>
                  书单
                </a>
              </li>
            
              <li>
                <a href="/music/">
                  <i class="fa fa-headphones" aria-hidden="true"></i>
                  歌单
                </a>
              </li>
            
          </ul>
        
      </li>
    
      <li>
        <a href="/comment/">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-pencil-square-o faa-tada" aria-hidden="true"></i>
            留言板
          </span>
        </a>
        
      </li>
    
      <li>
        <a href="/">
          <span class="faa-parent animated-hover">
            <i class="fa  fa-leaf faa-wrench" aria-hidden="true"></i>
            关于
          </span>
        </a>
        
          <ul class="sub-menu">
            
              <li>
                <a href="/about/">
                  <i class="fa fa-meetup" aria-hidden="true"></i>
                  我？
                </a>
              </li>
            
              <li>
                <a href="/theme-sakura/">
                  <i class="fa iconfont icon-sakura" aria-hidden="true"></i>
                  主题
                </a>
              </li>
            
          </ul>
        
      </li>
    
  </ul>
  <p style="text-align: center; font-size: 13px; color: #b9b9b9;">&copy 2019 hexo-sakura</p>
</div>
<button onclick="topFunction()" class="mobile-cd-top" id="moblieGoTop" title="Go to top" style="display: none;"><i class="fa fa-chevron-up" aria-hidden="true"></i></button>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
<!-- require MetingJS -->
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>
<style>
  .aplayer .aplayer-lrc {
    height: 35px;
  }
  .aplayer .aplayer-lrc p{
    font-size: 16px;
    font-weight: 700;
    line-height: 18px !important;
  }
  .aplayer .aplayer-lrc p.aplayer-lrc-current{
    color: #FF1493;
  }
  .aplayer.aplayer-narrow .aplayer-body{
    left: -66px !important;
  }
  .aplayer.aplayer-fixed .aplayer-lrc {
    display: none;
  }
  .aplayer .aplayer-lrc.aplayer-lrc-hide {
      display:none !important;
  }
  .aplayer.aplayer-fixed .lrc-show {
    display: block;
    background: rgba(255, 255, 255, 0.8);
  }
</style>
<meting-js

    id="5297427227"

    server="netease"

    type="playlist"

    fixed="true"

    autoplay="false"

    loop="all"

    order="list"

    preload="auto"

    volume="0.7"

    mutex="true"

</meting-js>
<script>
  $(function(){
    $('body').on('click', '.aplayer', function(){
      if($('.aplayer-button').hasClass('aplayer-play')) {
        $('.aplayer-lrc').removeClass('lrc-show');
      } else {
        $('.aplayer-lrc').addClass('lrc-show');
      }
    })
  });
</script>
  <script src="//instant.page/3.0.0" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>
  <script src="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/piao.js"></script>
</body>
</html>